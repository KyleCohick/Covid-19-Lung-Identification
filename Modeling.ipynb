{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coronavirus X-ray Classifier - Modelling\n",
    "\n",
    "Name: Kyle Cohick   \n",
    "Class: CSCI 349: Intro to Data Mining   \n",
    "Semester: 2020SP   \n",
    "Instructor: Brian King "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import itertools as it\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "All the data was prepped in my folders in the DataPrep_EDA.ipynb file, so the code below is just to load the data and make it available for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 232 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating instances of ImageDataGenerator for the training and validation imagesets\n",
    "train_imageDataGenerator = image.ImageDataGenerator(rescale = 1./255, # to what size it's being rescaled\n",
    "                                                    shear_range = 0.2, # shear intensity\n",
    "                                                    zoom_range = 0.2) # how much to zoom in\n",
    "\n",
    "val_imageDataGenerator = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# reshaping the test and validation images\n",
    "train_generator = train_imageDataGenerator.flow_from_directory(\n",
    "    'data/prepped_datasets/training', # directory containing the images\n",
    "    target_size = (224,224), # the dimensions to which all images found will be resized\n",
    "    batch_size = 32, # size of batches\n",
    "    class_mode = 'binary', # determines type of label array returned, since there are two classes, binary is fine\n",
    "    shuffle=True) # shuffles order images are interred\n",
    "validation_generator = val_imageDataGenerator.flow_from_directory(\n",
    "    'data/prepped_datasets/val',\n",
    "    target_size = (224,224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary', \n",
    "    shuffle=True)\n",
    "\n",
    "# sources:\n",
    "# https://keras.io/preprocessing/image/\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Layer Model\n",
    "This model will be built and tested against the hyperparamters in a 3-layer Sequential Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "model3 = Sequential()\n",
    "\n",
    "# input layer\n",
    "model3.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 1\n",
    "model3.add(Conv2D(32, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 2\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Sources:\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "# https://towardsdatascience.com/detecting-covid-19-using-deep-learning-262956b6f981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.9773 - accuracy: 0.5216 - val_loss: 0.6496 - val_accuracy: 0.8500\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.6350 - accuracy: 0.6164 - val_loss: 0.4130 - val_accuracy: 0.8833\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.5188 - accuracy: 0.7500 - val_loss: 0.3499 - val_accuracy: 0.8833\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.5521 - accuracy: 0.7931 - val_loss: 0.4045 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3477 - accuracy: 0.8534 - val_loss: 0.1694 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.5728 - accuracy: 0.8491 - val_loss: 0.2964 - val_accuracy: 0.8667\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.3410 - accuracy: 0.8879 - val_loss: 0.0993 - val_accuracy: 0.9667\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.3429 - accuracy: 0.8664 - val_loss: 0.1172 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2622 - accuracy: 0.9052 - val_loss: 0.2041 - val_accuracy: 0.9333\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4095 - accuracy: 0.8319 - val_loss: 0.1946 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "model3_result = model3.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705152</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.746789</td>\n",
       "      <td>0.556035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390296</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.544702</td>\n",
       "      <td>0.728448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.274096</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.516743</td>\n",
       "      <td>0.780172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.162740</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.508329</td>\n",
       "      <td>0.806035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.514610</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.218445</td>\n",
       "      <td>0.918103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.793025</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.433329</td>\n",
       "      <td>0.844828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.095991</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.437889</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.022465</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.166192</td>\n",
       "      <td>0.948276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.228743</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.104254</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.087123</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.331765</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_accuracy      loss  accuracy\n",
       "0  0.705152      0.500000  0.746789  0.556035\n",
       "1  0.390296      0.833333  0.544702  0.728448\n",
       "2  0.274096      0.883333  0.516743  0.780172\n",
       "3  0.162740      0.950000  0.508329  0.806035\n",
       "4  0.514610      0.850000  0.218445  0.918103\n",
       "5  0.793025      0.783333  0.433329  0.844828\n",
       "6  0.095991      0.966667  0.437889  0.896552\n",
       "7  0.022465      0.983333  0.166192  0.948276\n",
       "8  0.228743      0.966667  0.104254  0.965517\n",
       "9  0.087123      0.966667  0.331765  0.896552"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model3_result.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Covid': 0, 'Normal': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# get predictions for all in the Normal validation set\n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Normal/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Normal/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    pred=model3.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    y_true.append(1)\n",
    "    \n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Covid/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Covid/\" + file,target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    pred=model3.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    y_true.append(0)\n",
    "    \n",
    "y_true=np.array(y_true)\n",
    "y_pred=np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  2]\n",
      " [ 4 26]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        30\n",
      "           1       0.93      0.87      0.90        30\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.90      0.90      0.90        60\n",
      "weighted avg       0.90      0.90      0.90        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d581de7908>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# {'Covid': 0, 'Normal': 1}\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model, albeit the simplest in terms of complexity seems to perform the best with the highest f1-scores, a higher val_accuracy, but with a slightly higher loss rate. This will be the model that I perform hyperparameter tuning on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "model5 = Sequential()\n",
    "\n",
    "# input layer\n",
    "model5.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 1\n",
    "model5.add(Conv2D(32, (3, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 2\n",
    "model5.add(Conv2D(64, (3, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 3\n",
    "model5.add(Conv2D(128, (3, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 4\n",
    "model5.add(Conv2D(64, (3, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model5.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model5.add(Dense(64))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(1))\n",
    "model5.add(Activation('sigmoid'))\n",
    "\n",
    "model5.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7332 - accuracy: 0.4957 - val_loss: 0.6827 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.6805 - accuracy: 0.5733 - val_loss: 0.5779 - val_accuracy: 0.8333\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.5999 - accuracy: 0.6595 - val_loss: 0.3941 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.4060 - accuracy: 0.8103 - val_loss: 0.2092 - val_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4275 - accuracy: 0.8491 - val_loss: 1.2962 - val_accuracy: 0.5500\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4458 - accuracy: 0.8276 - val_loss: 0.2496 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.2111 - accuracy: 0.9095 - val_loss: 0.3127 - val_accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4525 - accuracy: 0.8147 - val_loss: 0.1614 - val_accuracy: 0.9333\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.2446 - accuracy: 0.9310 - val_loss: 0.1446 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.1753 - accuracy: 0.9397 - val_loss: 0.1387 - val_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "model5_result = model5.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682701</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.743064</td>\n",
       "      <td>0.495690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.577937</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.679885</td>\n",
       "      <td>0.573276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.394103</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.597993</td>\n",
       "      <td>0.659483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209245</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.412134</td>\n",
       "      <td>0.810345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.296224</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.427489</td>\n",
       "      <td>0.849138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.249650</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.421051</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.312706</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.214564</td>\n",
       "      <td>0.909483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.161442</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.470782</td>\n",
       "      <td>0.814655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.144557</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.223868</td>\n",
       "      <td>0.931035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.138656</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.154931</td>\n",
       "      <td>0.939655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_accuracy      loss  accuracy\n",
       "0  0.682701      0.500000  0.743064  0.495690\n",
       "1  0.577937      0.833333  0.679885  0.573276\n",
       "2  0.394103      0.933333  0.597993  0.659483\n",
       "3  0.209245      0.950000  0.412134  0.810345\n",
       "4  1.296224      0.550000  0.427489  0.849138\n",
       "5  0.249650      0.933333  0.421051  0.827586\n",
       "6  0.312706      0.916667  0.214564  0.909483\n",
       "7  0.161442      0.933333  0.470782  0.814655\n",
       "8  0.144557      0.916667  0.223868  0.931035\n",
       "9  0.138656      0.866667  0.154931  0.939655"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model5_result.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "# get predictions for all in the Normal validation set\n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Normal/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Normal/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    pred=model5.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    \n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Covid/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Covid/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    pred=model5.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    \n",
    "y_pred=np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0]\n",
      " [12 18]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        30\n",
      "           1       1.00      0.60      0.75        30\n",
      "\n",
      "    accuracy                           0.80        60\n",
      "   macro avg       0.86      0.80      0.79        60\n",
      "weighted avg       0.86      0.80      0.79        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d581d52ac8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# {'Covid': 0, 'Normal': 1}\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings here looked promising as the accuracy was high, but upon the test data, the scores were extremely low. The one positive thing that came out of this evaluation is the propensity for lack of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "model6 = Sequential()\n",
    "\n",
    "# input layer\n",
    "model6.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 1\n",
    "model6.add(Conv2D(32, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 2\n",
    "model6.add(Conv2D(64, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 3\n",
    "model6.add(Conv2D(128, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 4\n",
    "model6.add(Conv2D(128, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 5\n",
    "model6.add(Conv2D(64, (3, 3)))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model6.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model6.add(Dense(64))\n",
    "model6.add(Activation('relu'))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Dense(1))\n",
    "model6.add(Activation('sigmoid'))\n",
    "\n",
    "model6.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 12s 2s/step - loss: 0.7692 - accuracy: 0.5000 - val_loss: 0.6959 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.7083 - accuracy: 0.5431 - val_loss: 0.6859 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.6842 - accuracy: 0.5690 - val_loss: 0.6628 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.6426 - accuracy: 0.7026 - val_loss: 0.5336 - val_accuracy: 0.8833\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4859 - accuracy: 0.8017 - val_loss: 0.3836 - val_accuracy: 0.7833\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.3955 - accuracy: 0.8362 - val_loss: 1.5338 - val_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.6151 - accuracy: 0.7672 - val_loss: 0.4617 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 11s 1s/step - loss: 0.4562 - accuracy: 0.8362 - val_loss: 0.2722 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.4184 - accuracy: 0.8276 - val_loss: 0.2980 - val_accuracy: 0.9000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 12s 1s/step - loss: 0.4319 - accuracy: 0.8060 - val_loss: 0.1984 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model6_result = model6.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695885</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.775584</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.685942</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.708688</td>\n",
       "      <td>0.543103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.662804</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.683086</td>\n",
       "      <td>0.568965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533614</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.644973</td>\n",
       "      <td>0.702586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.383625</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.483926</td>\n",
       "      <td>0.801724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.533795</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.836207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.461688</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.603584</td>\n",
       "      <td>0.767241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.272190</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.448026</td>\n",
       "      <td>0.836207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.298029</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.419338</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.198373</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.442115</td>\n",
       "      <td>0.806035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_accuracy      loss  accuracy\n",
       "0  0.695885      0.500000  0.775584  0.500000\n",
       "1  0.685942      0.500000  0.708688  0.543103\n",
       "2  0.662804      0.500000  0.683086  0.568965\n",
       "3  0.533614      0.883333  0.644973  0.702586\n",
       "4  0.383625      0.783333  0.483926  0.801724\n",
       "5  1.533795      0.666667  0.416848  0.836207\n",
       "6  0.461688      0.900000  0.603584  0.767241\n",
       "7  0.272190      0.850000  0.448026  0.836207\n",
       "8  0.298029      0.900000  0.419338  0.827586\n",
       "9  0.198373      0.950000  0.442115  0.806035"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model6_result.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "# get predictions for all in the Normal validation set\n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Normal/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Normal/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    pred=model6.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    \n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Covid/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Covid/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    pred=model6.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    \n",
    "y_pred=np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  2],\n",
       "       [ 7, 23]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86        30\n",
      "           1       0.92      0.77      0.84        30\n",
      "\n",
      "    accuracy                           0.85        60\n",
      "   macro avg       0.86      0.85      0.85        60\n",
      "weighted avg       0.86      0.85      0.85        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d581efd288>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPxklEQVR4nO3de5BU5ZnH8d8zgKgzZCNykZsgSmkgBrBGdENRkNUkYFJBsxsL1kJql92hdgV1g0bXa3RTFWpXjBYxqQyXoMaAbilCaTRriEBRsUBQIqNDRCiDjAMTvKxcotDdz/4xHXaKGaa7mX77dL98P9ap6Tk9887zB/Wrx+e857S5uwAA4VQlXQAAxI6gBYDACFoACIygBYDACFoACKx76D9wdP8utjWgnTMGTki6BJSh1JEm6+oahWROjz7Du/z38kFHCwCBBe9oAaCkMumkK2iHoAUQl3Qq6QraIWgBRMU9k3QJ7RC0AOKSIWgBICw6WgAIjIthABAYHS0AhOXsOgCAwLgYBgCBMToAgMC4GAYAgdHRAkBgXAwDgMC4GAYAYbkzowWAsJjRAkBgjA4AIDA6WgAILH006QraIWgBxKUMRwd8OCOAuHgm/6MTZjbEzF42s0Yze9PMbsqe/76ZNZnZ1uxxVa6S6GgBxKV4HW1K0jx3f83MeknaYmYvZd/7kbs/kO9CBC2AuBQpaN29WVJz9vUBM2uUNOhk1mJ0ACAqnj6a92FmdWa2uc1R19GaZjZM0lhJG7On5pjZG2a21MzOylUTQQsgLgXMaN293t1r2xz1xy9nZjWSnpZ0s7t/Iumnks6XNEatHe+CXCUxOgAQlyLuOjCzHmoN2Sfc/RlJcvd9bd5fJOm5XOsQtADiUqQbFszMJC2R1OjuD7Y5PyA7v5WkayQ15FqLoAUQl+J1tOMlzZC0zcy2Zs/dIWm6mY2R5JLelTQ710IELYC4FKmjdfcNkqyDt35V6FoELYC4pHjwNwCExUNlACCwMnzWAUELIC50tAAQGB0tAARGRwsAgbHrAAACc0+6gnYIWgBxYUYLAIERtAAQGBfDACCwdDrpCtohaAHEhdEBAARG0AJAYMxoASAsz7CPFgDCYnQAAIGx6wAAAqOjBYDACNpTR/O+P+mO/3hA+z/8SFVm+rupUzTj2qu1/e2duv+/FuqzI0fVrVs33X3LDbp45IVJl4sEDB48UMuWPqz+5/RVJpPR4sVPaOGPlyRdVuXjoTKnju7duunWuf+skRdeoEOHDuvaWTfqy5eO1YKfLNG//ON1mvDXl2r97zZpwU+WaNmP/zPpcpGAVCqlW793n17f2qCammpt2viifrNmvRobdyRdWmWrxI7WzC6SNFXSILV+jvn7kla7e2Pg2ipa3z691bdPb0lSdfWZGj50iPb96QOZmQ4eOixJOnjosPr1OTvJMpGgvXtbtHdviyTp4MFD2r59hwYNPIeg7apK295lZrdJmi5phaRN2dODJS03sxXuPj9wfVFoat6nxh079aVRF+q2m2Zr9nfv0gOPLJZnXL/42YKky0MZGDp0sMaM/qI2bno96VIqXxnuOqjK8f4sSZe6+3x3/0X2mC9pXPa9DplZnZltNrPNix9bXsx6K87hw3/Wv935A91242zVVFfryZXP67a5dVqz8nF978Y63fPDh5IuEQmrrj5TTz25SN+95V4dOHAw6XIqnmcyeR+lkitoM5IGdnB+QPa9Drl7vbvXunvtP10/vSv1VbSjqZRuvvMH+sbXvqKvThovSVr9wm90Zfb11/9mgra99YckS0TCunfvrv9+cpGWL1+pZ599Iely4pDx/I8SyTWjvVnSGjPbIem97LlzJV0gaU7Iwiqdu+ueHz6k4UOHaOa0bx8737fP2Xr19W0ad8mXtHHLVg0dMijBKpG0RfUL1Lj9HT30cH3SpcSjDJ91YJ5jK4SZVal1VDBIkknaI+lVd89rEHJ0/67ym0yXwGu/b9D1/3qrRpw/TFXW+j8ON82eqZrqMzX/4Z8plU6r52mn6a55N2jURSMSrrb0zhg4IekSEjf+y5dq3dpn9ca2t5TJdld33z1fL7z424QrS07qSJN1dY1D91+Xd+ZU3/NEl/9ePnIGbVedqkGLzhG06EhRgvaeafkH7f0rShK07KMFEJcyHB0QtADiUmn7aAGg0pRy21a+CFoAcSnDjjbXPloAqCxF2kdrZkPM7GUzazSzN83spuz53mb2kpntyH49K1dJBC2AuKTT+R+dS0ma5+5fkHS5pBvMbKSk2yWtcfcRktZkv+8UQQsgKp7xvI9O13FvdvfXsq8PSGpU6/0EUyU9mv2xRyVdnasmghZAXAoYHbR9Lkv2qOtoSTMbJmmspI2S+rt7s9QaxpL65SqJi2EA4lLArgN3r5fU6f3PZlYj6WlJN7v7J2aF3+NA0AKISxF3HZhZD7WG7BPu/kz29D4zG+DuzWY2QFJLrnUYHQCIS/F2HZikJZIa3f3BNm+tljQz+3qmpFW5SqKjBRAVTxfthoXxkmZI2mZmW7Pn7pA0X9JTZjZL0m5J38m1EEELIC5FGh24+wa1PrGwI1cUshZBCyAqubZtJYGgBRAXghYAAiu/Z8oQtADi4qnyS1qCFkBcyi9nCVoAceFiGACERkcLAGHR0QJAaHS0ABCWp5KuoD2CFkBUyvDTxglaAJEhaAEgLDpaAAiMoAWAwDxd+EfNhEbQAogKHS0ABOYZOloACIqOFgACc6ejBYCg6GgBILAMuw4AICwuhgFAYAQtAATm5fc4WoIWQFzoaAEgMLZ3AUBgaXYdAEBYdLQAEBgzWgAIjF0HABAYHS0ABJbOVCVdQjsELYColOPooPyiHwC6IOOW95GLmS01sxYza2hz7vtm1mRmW7PHVbnWIWgBRMXd8j7ysEzS5A7O/8jdx2SPX+VahNEBgKgUc3Tg7uvNbFhX1wketFMvmRP6T6ACHVg0I+kSEKl8RgJ/YWZ1kuranKp39/o8fnWOmV0vabOkee7+UWc/zOgAQFTSmaq8D3evd/faNkc+IftTSedLGiOpWdKCXL9A0AKIihdwnNT67vvcPe3uGUmLJI3L9TvMaAFEpZDRwckwswHu3pz99hpJDZ39vETQAohMMR8qY2bLJU2S1MfM9ki6V9IkMxuj1qb4XUmzc61D0AKISjE/BNfdp3dwekmh6xC0AKLi4lkHABBUiufRAkBYdLQAEFgxZ7TFQtACiAodLQAERkcLAIGl6WgBIKwy/CQbghZAXDJ0tAAQVhl+kg1BCyAuXAwDgMAyxugAAIJKJ11ABwhaAFFh1wEABMauAwAIjF0HABAYowMACIztXQAQWJqOFgDCoqMFgMAIWgAIrAw/MoygBRAXOloACIxbcAEgMPbRAkBgjA4AIDCCFgAC41kHABAYM1oACIxdBwAQWKYMhwcELYCocDEMAAIrv35Wqkq6AAAopkwBRy5mttTMWsysoc253mb2kpntyH49K9c6BC2AqKTM8z7ysEzS5OPO3S5pjbuPkLQm+32nCFoAUfECjpxrua+X9OFxp6dKejT7+lFJV+dah6AFEJVCRgdmVmdmm9scdXn8if7u3ixJ2a/9cv0CF8MARKWQ7V3uXi+pPlw1rehoAUSlmKODE9hnZgMkKfu1JdcvELQAolLMXQcnsFrSzOzrmZJW5foFRgcAopIu4k5aM1suaZKkPma2R9K9kuZLesrMZknaLek7udYhaAFEpZh3hrn79BO8dUUh6xC0AKLiZXhvGEELICo86+AUNWj4IN3+yP/fPDLg3AF6/MHHtWpJzhk6IrP3k8O6a/UWfXDoU5mZ/nbMMF037gI9su4trX27WWam3tU9df83L1G/XmckXW5F4uldp6imXU2aO2WuJKmqqkqPbXpMr7z4SsJVIQndqqo078qL9YVzPq9Dnx3V9J+/rMvP66eZl4/QDRNHSpJ++epO1W/YrrumjE242spUfjFL0Jbc6PGjtXf3XrU05dx6hwj1rTldfWtOlyRV9+yh4Wf3UsvBT3V+388d+5k/H03JVIYfE1AhUmUYtQRtiU381kStXbU26TJQBpo+PqTt+/5XFw9sffjTwrVv6rlt76mmZ3ctum5CwtVVrnK8GHbSNyyY2T908t6x+4d3H9x9sn8iOt17dNdlX71MG57fkHQpSNjhIynd8swm3Xrlxarp2UOSNHfSKP167mRd9cUhWrFlV8IVVq4S3LBQsK7cGXbfid5w93p3r3X32nNrzu3Cn4hL7aRa7WzYqY/3f5x0KUjQ0XRG857eqKtGDdYVFw1q9/6UUUO0ZntTApXFwQv4r1Q6HR2Y2RsnektS/+KXE7eJUydq3ap1SZeBBLm77nv+NZ3Xp5dmXDbi2Pk/fnhQQ3vXSJLWvd2s887ulVSJFa8St3f1l/R1SR8dd94k/S5IRZHqeXpPjZ0wVgv/fWHSpSBBW/d8oOca3tOIvp/TtYt/K0maO2mknv39H/XuBwdUZaYBf3Wm7pwyJuFKK1fay29Gmyton5NU4+5bj3/DzNYGqShSn336maaNnpZ0GUjY2CF9tPWOa9qdn3DBOQlUE6eK20fr7rM6ee/vi18OAHRNOe46YHsXgKhU4owWACpKxY0OAKDSMDoAgMAqcdcBAFQURgcAEBgXwwAgMGa0ABAYowMACMy5GAYAYRXz48aLhaAFEBVGBwAQGKMDAAiMjhYAAmN7FwAExi24ABAYowMACIygBYDA2HUAAIHR0QJAYOw6AIDA0l5+D0okaAFEpZgzWjN7V9IBSWlJKXevPZl1CFoAUQkwo/2Ku+/vygIELYColOOMtirpAgCgmDLueR9mVmdmm9scdcct55L+x8y2dPBe3uhoAUSlkI7W3esl1XfyI+Pd/X0z6yfpJTPb7u7rC62JjhZAVNKeyfvIxd3fz35tkbRS0riTqYmgBRCVQkYHnTGzajPr9ZfXkr4mqeFkamJ0ACAqRbwY1l/SSjOTWrPyl+7+4sksRNACiEquTjVf7r5L0uhirEXQAohKOW7vImgBRCXt6aRLaIegBRAVHpMIAIHxmEQACIyOFgACK9aug2IiaAFEhV0HABAYD/4GgMCY0QJAYMxoASAwOloACIx9tAAQGB0tAATGrgMACIyLYQAQGKMDAAiMO8MAIDA6WgAIrBxntFaO6R8rM6vLfo48cAz/LuLHx42XVl3SBaAs8e8icgQtAARG0AJAYARtaTGHQ0f4dxE5LoYBQGB0tAAQGEELAIERtCViZpPN7A9m9o6Z3Z50PUiemS01sxYza0i6FoRF0JaAmXWT9IikKZJGSppuZiOTrQplYJmkyUkXgfAI2tIYJ+kdd9/l7kckrZA0NeGakDB3Xy/pw6TrQHgEbWkMkvRem+/3ZM8BOAUQtKVhHZxjXx1wiiBoS2OPpCFtvh8s6f2EagFQYgRtabwqaYSZnWdmp0maJml1wjUBKBGCtgTcPSVpjqRfS2qU9JS7v5lsVUiamS2X9IqkC81sj5nNSromhMEtuAAQGB0tAARG0AJAYAQtAARG0AJAYAQtAARG0AJAYAQtAAT2fxnj3L4pfs1xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# {'Covid': 0, 'Normal': 1}\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 6-layered model did significantly better than the 5-layered model, with f1-scores higher across the board. However, the only issue is this model does contain false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a dictionary containing all the hyperparamters I would like to train. Unfortunately because I'm using generators to handle my data, I instead have to use my own way to cross check these hyperparamters. So, I've compiled all the combinations into a list and I use a function to create the 3-layer keras model using those hyperparamters and storying the results. From here I'll select the best model off a combination of loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('relu', 8, 5, 'adam'), ('relu', 8, 5, 'sgd'), ('relu', 8, 5, 'rmsprop'), ('relu', 8, 10, 'adam'), ('relu', 8, 10, 'sgd'), ('relu', 8, 10, 'rmsprop'), ('relu', 8, 15, 'adam'), ('relu', 8, 15, 'sgd'), ('relu', 8, 15, 'rmsprop'), ('relu', 16, 5, 'adam'), ('relu', 16, 5, 'sgd'), ('relu', 16, 5, 'rmsprop'), ('relu', 16, 10, 'adam'), ('relu', 16, 10, 'sgd'), ('relu', 16, 10, 'rmsprop'), ('relu', 16, 15, 'adam'), ('relu', 16, 15, 'sgd'), ('relu', 16, 15, 'rmsprop'), ('relu', 32, 5, 'adam'), ('relu', 32, 5, 'sgd'), ('relu', 32, 5, 'rmsprop'), ('relu', 32, 10, 'adam'), ('relu', 32, 10, 'sgd'), ('relu', 32, 10, 'rmsprop'), ('relu', 32, 15, 'adam'), ('relu', 32, 15, 'sgd'), ('relu', 32, 15, 'rmsprop'), ('tanh', 8, 5, 'adam'), ('tanh', 8, 5, 'sgd'), ('tanh', 8, 5, 'rmsprop'), ('tanh', 8, 10, 'adam'), ('tanh', 8, 10, 'sgd'), ('tanh', 8, 10, 'rmsprop'), ('tanh', 8, 15, 'adam'), ('tanh', 8, 15, 'sgd'), ('tanh', 8, 15, 'rmsprop'), ('tanh', 16, 5, 'adam'), ('tanh', 16, 5, 'sgd'), ('tanh', 16, 5, 'rmsprop'), ('tanh', 16, 10, 'adam'), ('tanh', 16, 10, 'sgd'), ('tanh', 16, 10, 'rmsprop'), ('tanh', 16, 15, 'adam'), ('tanh', 16, 15, 'sgd'), ('tanh', 16, 15, 'rmsprop'), ('tanh', 32, 5, 'adam'), ('tanh', 32, 5, 'sgd'), ('tanh', 32, 5, 'rmsprop'), ('tanh', 32, 10, 'adam'), ('tanh', 32, 10, 'sgd'), ('tanh', 32, 10, 'rmsprop'), ('tanh', 32, 15, 'adam'), ('tanh', 32, 15, 'sgd'), ('tanh', 32, 15, 'rmsprop')]\n"
     ]
    }
   ],
   "source": [
    "# what I would use if I could use GridSearchCV\n",
    "param_grid = {\n",
    "    'optimizer' : ['adam', 'sgd', 'rmsprop'],\n",
    "    'activation' : ['relu', 'tanh'],\n",
    "    'epochs' : [5, 10, 15],\n",
    "    'epoch_steps' : [8, 16, 32]\n",
    "}\n",
    "\n",
    "# making a list of all combinations to try\n",
    "all_params = sorted(param_grid)\n",
    "param_lists = list(it.product(*(param_grid[param] for param in all_params)))\n",
    "print(param_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(activation, epochs, epoch_steps, optimizer):\n",
    "    # model creation\n",
    "    model = Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # hidden layer 1\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # hidden layer 2\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model_result = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=epoch_steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=2,\n",
    "        verbose=0)\n",
    "    \n",
    "    return model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model_results = pd.DataFrame(columns=['params', 'val_loss', 'val_accuracy', 'loss', 'accuracy'])\n",
    "\n",
    "#\n",
    "for param_list in param_lists:\n",
    "    model_results = create_keras_model(param_list[0], param_list[1], param_list[2], param_list[3])\n",
    "    new_entry = pd.Series([param_list] + (list(pd.DataFrame(model_results.history).iloc[-1])), index=['params', 'val_loss', 'val_accuracy', 'loss', 'accuracy'])\n",
    "    new_entry = new_entry.to_frame().T\n",
    "    all_model_results = all_model_results.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_model_results.sort_values([\"accuracy\", \"loss\"], ascending=False) \n",
    "# the output of this value took 4 hours to compile, unfortunately I lost the table, but here it exists in jpg\n",
    "# data/display_images/hyperparameter_table.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(relu, 32, 15, adam) will be the chosen hyperparameters for the model as they provided the higest accuracy and extremely low loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.5068 - accuracy: 0.7315 - val_loss: 0.1976 - val_accuracy: 0.9667\n",
      "Epoch 2/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.2700 - accuracy: 0.9028 - val_loss: 0.0657 - val_accuracy: 0.9500\n",
      "Epoch 3/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.1450 - accuracy: 0.9560 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 4/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.1393 - accuracy: 0.9649 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 5/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0982 - accuracy: 0.9699 - val_loss: 0.0061 - val_accuracy: 0.9833\n",
      "Epoch 6/32\n",
      "15/15 [==============================] - 20s 1s/step - loss: 0.1219 - accuracy: 0.9534 - val_loss: 0.1040 - val_accuracy: 0.9333\n",
      "Epoch 7/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.1312 - accuracy: 0.9474 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 8/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.1083 - accuracy: 0.9583 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 9/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0807 - accuracy: 0.9715 - val_loss: 0.2393 - val_accuracy: 0.9500\n",
      "Epoch 11/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.1000 - accuracy: 0.9745 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 12/32\n",
      "15/15 [==============================] - 20s 1s/step - loss: 0.0535 - accuracy: 0.9804 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 13/32\n",
      "15/15 [==============================] - 23s 2s/step - loss: 0.0645 - accuracy: 0.9803 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 14/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 15/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0591 - accuracy: 0.9861 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 16/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0401 - accuracy: 0.9884 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 17/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 9.1573e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.0085 - val_accuracy: 0.9833\n",
      "Epoch 19/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 0.0113 - val_accuracy: 0.9833\n",
      "Epoch 20/32\n",
      "15/15 [==============================] - 23s 2s/step - loss: 0.0317 - accuracy: 0.9931 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 21/32\n",
      "15/15 [==============================] - 23s 2s/step - loss: 0.0350 - accuracy: 0.9931 - val_loss: 0.0485 - val_accuracy: 0.9833\n",
      "Epoch 22/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0320 - accuracy: 0.9861 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 23/32\n",
      "15/15 [==============================] - 22s 1s/step - loss: 0.0314 - accuracy: 0.9846 - val_loss: 0.0221 - val_accuracy: 0.9833\n",
      "Epoch 24/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0411 - accuracy: 0.9907 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 25/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0329 - accuracy: 0.9838 - val_loss: 0.0035 - val_accuracy: 0.9667\n",
      "Epoch 26/32\n",
      "15/15 [==============================] - 20s 1s/step - loss: 0.0163 - accuracy: 0.9977 - val_loss: 0.0025 - val_accuracy: 0.9667\n",
      "Epoch 27/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0222 - accuracy: 0.9907 - val_loss: 1.5318e-04 - val_accuracy: 0.9833\n",
      "Epoch 28/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0164 - accuracy: 0.9977 - val_loss: 0.0026 - val_accuracy: 0.9833\n",
      "Epoch 29/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0297 - accuracy: 0.9884 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 30/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 31/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0211 - accuracy: 0.9884 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 32/32\n",
      "15/15 [==============================] - 21s 1s/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 0.0127 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# model creation\n",
    "final_model = Sequential()\n",
    "\n",
    "# input layer\n",
    "final_model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "final_model.add(Activation('relu'))\n",
    "final_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 1\n",
    "final_model.add(Conv2D(32, (3, 3)))\n",
    "final_model.add(Activation('relu'))\n",
    "final_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# hidden layer 2\n",
    "final_model.add(Conv2D(64, (3, 3)))\n",
    "final_model.add(Activation('relu'))\n",
    "final_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "final_model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "final_model.add(Dense(64))\n",
    "final_model.add(Activation('relu'))\n",
    "final_model.add(Dropout(0.5))\n",
    "final_model.add(Dense(1))\n",
    "final_model.add(Activation('sigmoid'))\n",
    "\n",
    "final_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model_result = final_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=15,\n",
    "    epochs=32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.197558</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.516078</td>\n",
       "      <td>0.731481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065742</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.273052</td>\n",
       "      <td>0.902778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.154168</td>\n",
       "      <td>0.956019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141248</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.096506</td>\n",
       "      <td>0.969907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.103996</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.126376</td>\n",
       "      <td>0.953431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137095</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116563</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060174</td>\n",
       "      <td>0.983796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.239303</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.084459</td>\n",
       "      <td>0.971491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086137</td>\n",
       "      <td>0.974537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.012880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058875</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.030370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067607</td>\n",
       "      <td>0.980263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057621</td>\n",
       "      <td>0.981481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.008339</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043961</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038733</td>\n",
       "      <td>0.988426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027754</td>\n",
       "      <td>0.990741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.008459</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.037827</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>0.988426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.009612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032011</td>\n",
       "      <td>0.993056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.048519</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.037780</td>\n",
       "      <td>0.993056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.018272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035096</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>0.984649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.012126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.990741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.035989</td>\n",
       "      <td>0.983796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.997685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.990741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.997685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.008686</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031269</td>\n",
       "      <td>0.988426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042866</td>\n",
       "      <td>0.986842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.017097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.988426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.012663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019718</td>\n",
       "      <td>0.995370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss  val_accuracy      loss  accuracy\n",
       "0   0.197558      0.966667  0.516078  0.731481\n",
       "1   0.065742      0.950000  0.273052  0.902778\n",
       "2   0.013660      1.000000  0.154168  0.956019\n",
       "3   0.025809      1.000000  0.141248  0.964912\n",
       "4   0.006148      0.983333  0.096506  0.969907\n",
       "5   0.103996      0.933333  0.126376  0.953431\n",
       "6   0.030131      1.000000  0.137095  0.947368\n",
       "7   0.007207      1.000000  0.116563  0.958333\n",
       "8   0.001385      1.000000  0.060174  0.983796\n",
       "9   0.239303      0.950000  0.084459  0.971491\n",
       "10  0.005278      1.000000  0.086137  0.974537\n",
       "11  0.012880      1.000000  0.058875  0.980392\n",
       "12  0.030370      1.000000  0.067607  0.980263\n",
       "13  0.003541      1.000000  0.057621  0.981481\n",
       "14  0.008339      1.000000  0.043961  0.986111\n",
       "15  0.003001      1.000000  0.038733  0.988426\n",
       "16  0.000916      1.000000  0.027754  0.990741\n",
       "17  0.008459      0.983333  0.037827  0.986111\n",
       "18  0.011334      0.983333  0.033881  0.988426\n",
       "19  0.009612      1.000000  0.032011  0.993056\n",
       "20  0.048519      0.983333  0.037780  0.993056\n",
       "21  0.018272      1.000000  0.035096  0.986111\n",
       "22  0.022102      0.983333  0.026581  0.984649\n",
       "23  0.012126      1.000000  0.040643  0.990741\n",
       "24  0.003548      0.966667  0.035989  0.983796\n",
       "25  0.002450      0.966667  0.017862  0.997685\n",
       "26  0.000153      0.983333  0.024187  0.990741\n",
       "27  0.002649      0.983333  0.015891  0.997685\n",
       "28  0.008686      1.000000  0.031269  0.988426\n",
       "29  0.011300      1.000000  0.042866  0.986842\n",
       "30  0.017097      1.000000  0.022933  0.988426\n",
       "31  0.012663      1.000000  0.019718  0.995370"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_model_result.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "\n",
    "# get predictions for all in the Normal validation set\n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Normal/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Normal/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    pred=final_model.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    \n",
    "for file in os.listdir(\"./data/prepped_datasets/val/Covid/\"):\n",
    "    img=image.load_img(\"./data/prepped_datasets/val/Covid/\" + file, target_size=(224,224))\n",
    "    img=image.img_to_array(img)\n",
    "    img=np.expand_dims(img,axis=0)\n",
    "    pred=final_model.predict_classes(img)\n",
    "    y_pred.append(pred[0,0])\n",
    "    \n",
    "y_pred=np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30,  0],\n",
       "       [ 0, 30]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2522049f988>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# {'Covid': 0, 'Normal': 1}\n",
    "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
